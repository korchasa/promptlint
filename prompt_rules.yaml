prompt_rules:

  - name: "Clear Task Description"
    rule: "The prompt must start with a clear high-level description of the task."
    reason: "This ensures the model understands the overall context and purpose."
    fix: "Add a clear introductory sentence that defines the task and context."
    badExample: "Summarize the following text: {text}"
    goodExample: "You are an expert summarizer. Summarize the following text by identifying the main points: {text}"

  - name: "Include Examples"
    rule: "Include one-shot or few-shot examples to demonstrate the expected format, style, output, or specific syntax."
    reason: "Examples help the model infer the correct output format, style, and recognize desired patterns or required syntax."
    fix: "Add clear examples that illustrate the desired output or code style."
    badExample: "Write a function that adds numbers."
    goodExample: "Example:\n```\n# Write a function that adds two numbers\n def add(a, b):\n     return a + b\n```"

  - name: "Provide Context"
    rule: "Include necessary context such as libraries, APIs, databases, or descriptions of non-standard functions."
    reason: "Additional reference information helps the model interpret the task correctly and understand unfamiliar elements."
    fix: "Append details (e.g., library names, API endpoints, function descriptions) to the prompt."
    badExample: "Use the new API to process data."
    goodExample: "The new API 'X' has a function 'doY' that accepts Z. Process the data using this function."

  - name: "Include Conversation History"
    rule: "Include previous messages and results in multi-turn dialogues to maintain context for multi-step tasks."
    reason: "This prevents ambiguity and preserves continuity."
    fix: "Append relevant conversation history or references to previous exchanges."
    badExample: "Next, process the input."
    goodExample: "Based on the previous conversation: [previous messages]. Now, process the input: {input}."

  - name: "Balance Length"
    rule: "Ensure both the prompt and expected response have appropriate length - detailed enough but not excessive."
    reason: "A balanced length provides complete context without affecting performance, and helps control response verbosity."
    fix: "Adjust prompt length to include critical details while avoiding verbosity, and specify word count for responses when needed."
    badExample: "Explain quantum computing."
    goodExample: "Explain quantum computing in approximately 200 words, focusing on the key concepts."

  - name: "Be Specific and Clear"
    rule: "Clearly specify the required context, outcome, format, and style in the prompt using templates, markers, or delimiters when appropriate."
    reason: "Detailed, clear instructions lead to more accurate and relevant responses with consistent formatting."
    fix: "Expand the prompt to include detailed requirements and use formatting tools to make expectations explicit."
    badExample: "Summarize the text."
    goodExample: "Summarize the text as follows: 'Summary: ...' or use format:\n```\nFrench: [text]\nEnglish:\n```"

  - name: "Use Proxy Tasks"
    rule: "Utilize analogies or proxies to describe complex or abstract tasks."
    reason: "Helps simplify complex tasks by relating them to familiar concepts."
    fix: "Include an analogy or reference description in the prompt."
    badExample: "Explain the concept."
    goodExample: "Explain the concept as if you were a professor explaining it to students."

  - name: "Use Step-by-Step Approach"
    rule: "Divide complex tasks into clear, sequential steps and encourage chain-of-thought reasoning."
    reason: "Breaking down tasks step by step allows the model to process complex problems methodically and provide intermediate reasoning."
    fix: "Add numbered steps, explicit process instructions, or phrases like 'Let's think step by step'."
    badExample: "Solve the problem."
    goodExample: "Step 1: Analyze the problem. Step 2: Outline the solution. Step 3: Provide the answer."

  - name: "Avoid Quick Conclusions"
    rule: "Instruct the model to refrain from forming early conclusions that it then justifies."
    reason: "Prevents the model from merely rationalizing a premature answer."
    fix: "Add an instruction such as 'Do not rush to a conclusion; first break down the problem.'"
    badExample: "Is the solution correct?"
    goodExample: "First, break down the problem into components, then determine if the solution is correct."

  - name: "Use Meta-Prompting Techniques"
    rule: "Employ meta-prompts to provide overarching context, guide specific tasks, evaluate output quality, or instruct self-critique."
    reason: "Meta-prompts improve the quality of task instructions and enable the model to evaluate and improve its own outputs."
    fix: "Incorporate meta-prompts that outline general tasks or evaluation criteria, and test multiple variations."
    badExample: "Use a generic evaluation prompt."
    goodExample: "Review the solution using these criteria: accuracy, completeness, clarity, and efficiency."

  - name: "Start With Instructions"
    rule: "Put clear instructions at the beginning of the prompt and separate them from the context using delimiters (e.g., `###` or `\"\"\"`)."
    reason: "This clarifies the separation between instructions and context."
    fix: "Reformat the prompt to have an instruction section at the start, separated by delimiters."
    badExample: "Summarize the following text: {text}"
    goodExample: "Summarize the following text as instructed:\n```\n### Instructions:\nTranslate to French.\n### Text:\n{text}\n```"

  - name: "Use Positive Instructions"
    rule: "Instead of stating what not to do, clearly instruct what should be done."
    reason: "Positive instructions lead to clearer and more focused outputs."
    fix: "Rephrase the prompt to include explicit action directives."
    badExample: "Do not write a long story."
    goodExample: "Write a concise summary of the text."

  - name: "Use Code Prompts"
    rule: "Include leading words (e.g., `import`, `SELECT`) to guide the model in generating code."
    reason: "Leading words help orient the model towards the desired coding language or structure."
    fix: "Prepend the prompt with code-specific leading words."
    badExample: "Write a function that adds two numbers."
    goodExample: "```\nimport\n# Write a Python function that adds two numbers:\ndef add(a, b):\n    return a + b\n```"

  - name: "Use Generate Feature"
    rule: "Leverage the Generate Anything feature to generate prompts based on task descriptions."
    reason: "This feature can help quickly create tailored prompts."
    fix: "Utilize the feature to generate a base prompt and then refine it."
    badExample: "Manually craft a prompt without assistance."
    goodExample: "Use Generate Anything to produce a base prompt, then iterate on it."

  - name: "Assign Persona"
    rule: "Define a specific role or persona for the LLM to tailor its responses."
    reason: "A defined persona guides the model to generate responses suited to a particular context."
    fix: "Add a clear role assignment at the beginning of the prompt."
    badExample: "Explain quantum computing."
    goodExample: "You are a quantum physics professor teaching first-year university students. Explain quantum computing in simple terms."

  - name: "Include Edge Cases"
    rule: "Specify how to handle edge cases and exceptions."
    reason: "Clearer handling of edge cases leads to more robust and reliable outputs."
    fix: "Add instructions for edge case handling."
    badExample: "Sort this array."
    goodExample: "Sort this array. If the array is empty, return an empty array. If a value is null, place it at the end."

  - name: "Structure Complex Prompts"
    rule: "For complex tasks, break down the prompt into clearly labeled sections."
    reason: "Organized prompts are easier for the model to parse and follow."
    fix: "Use headings, numbered lists, or other structural elements."
    badExample: "Write code to analyze data and generate a report."
    goodExample: "Task: Write Python code with three sections. Step 1: Data loading. Step 2: Statistical analysis. Step 3: Report generation."

  - name: "Request Multiple Options"
    rule: "Ask for alternative approaches or multiple perspectives when appropriate."
    reason: "Multiple options enable more comprehensive coverage of a topic."
    fix: "Explicitly request various approaches or interpretations."
    badExample: "How should I solve this problem?"
    goodExample: "Propose three different approaches to solving this problem, including their respective advantages and disadvantages."

  - name: "Set Authority Level"
    rule: "Specify whether to use authoritative statements or more exploratory language."
    reason: "The level of certainty in the response should match the nature of the topic."
    fix: "Add instructions about the desired authority level."
    badExample: "Explain this scientific concept."
    goodExample: "Explain this scientific concept, clearly distinguishing between established facts and areas where scientific consensus is still developing."

  - name: "Assign Difficulty Level"
    rule: "Indicate the appropriate complexity or technical level for the response."
    reason: "This ensures that the output is accessible to the intended audience."
    fix: "Specify the target audience expertise level."
    badExample: "Explain quantum computing."
    goodExample: "Explain quantum computing to a high school student who has basic knowledge of physics."


